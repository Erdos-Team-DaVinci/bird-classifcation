{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647b364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import set_style\n",
    "import seaborn as sns\n",
    "## This sets the plot style\n",
    "## to have a grid on a white background\n",
    "set_style(\"whitegrid\")\n",
    "\n",
    "#For machine learning methods\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#For neural network\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing import image\n",
    "## Importing the things\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras.utils import to_categorical\n",
    "import json\n",
    "\n",
    "#import skimage\n",
    "#print(skimage.__version__)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## Checks what is tensorflow running on\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "## This imports datasets stored in keras\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bff2c4",
   "metadata": {},
   "source": [
    "# 1. Import data as notebook 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37086a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "birds_db = pd.read_csv('./birds_archive/birds.csv')\n",
    "birds_db.value_counts('labels')\n",
    "birds_class = pd.read_csv('./birds_archive/class_dict.csv')\n",
    "birds_names = pd.read_csv('./birds_archive/birds latin names.csv')\n",
    "\n",
    "print(birds_names.head(2))\n",
    "print('..................................\\n')\n",
    "print(birds_class.head(2))\n",
    "print('..................................\\n')\n",
    "(birds_db.tail())\n",
    "\n",
    "birds_names_subset = birds_names.sample(100, random_state=42)\n",
    "birds_names_subset = birds_names_subset.rename(columns={'class':'labels'})\n",
    "print(birds_names_subset)\n",
    "\n",
    "birds_db_subset = birds_db[birds_db['labels'].isin(birds_names_subset['labels'])].dropna()\n",
    "birds_db_subset = birds_db_subset.reset_index()\n",
    "birds_db_subset\n",
    "\n",
    "label_dict = {i:birds_names_subset['labels'].values[i] for i in range(len(birds_names_subset))}\n",
    "labelsDF = pd.DataFrame(label_dict.items(), columns=['label_index','label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ff6377",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "from tensorflow.keras.preprocessing import image\n",
    "# this piece loads image data into a list and a numpy array \n",
    "bird_labels = []\n",
    "bird_label_num = []\n",
    "birdImage_list_jpg = []\n",
    "birdImage_list = []\n",
    "#birdImage_arr = np.zeros(1)\n",
    "#birdImage_arr = np.delete(birdImage_ar, 0)\n",
    "for indx, filepath, label in zip(range(len(birds_db_subset)), birds_db_subset.filepaths, birds_db_subset.labels):\n",
    "    try:\n",
    "        bird_labels.append(label)\n",
    "        bird_label_num.append(labelsDF.loc[labelsDF['label'] == label, 'label_index'].values[0])\n",
    "        #print(filepath)\n",
    "        img = tf.keras.utils.load_img(\n",
    "                './birds_archive/Data/'+filepath,\n",
    "                grayscale=False,\n",
    "                color_mode='rgb',\n",
    "                target_size=None,\n",
    "                interpolation='nearest',\n",
    "                keep_aspect_ratio=False)\n",
    "        \n",
    "        # list of bird images in jpg format \n",
    "        birdImage_list_jpg.append(img)  \n",
    "        \n",
    "        img_arr = image.img_to_array(img)\n",
    "        birdImage_list.append(img_arr)\n",
    "        img_arr_ = img_arr.reshape((1,) + img_arr.shape)\n",
    "        # List containng all bird images each in array format \n",
    "        #birdImage_arr = np.append(birdImage_arr, img_arr)\n",
    "    except (TypeError, IndexError) as e:\n",
    "        pass\n",
    "        #print(indx, label)\n",
    "\n",
    "# Numpy array N x 224x224x3 containing all bird images \n",
    "birdImage_arr = np.array(birdImage_list) \n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(birdImage_arr, (pd.DataFrame(bird_label_num)[0]).values,\n",
    "                                                                          test_size=0.15, shuffle=True, random_state=44)\n",
    "print(X_train.shape)\n",
    "print()\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bffbb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,4,figsize=(18,18))\n",
    "ax[0].imshow(img_arr[:, : , :].astype('uint8'))\n",
    "ax[1].imshow(img_arr[:, : , 0].astype('uint8'))\n",
    "ax[2].imshow(img_arr[:, : , 1].astype('uint8'))\n",
    "ax[3].imshow(img_arr[:, : , 2].astype('uint8'))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa8989b",
   "metadata": {},
   "source": [
    "# 2. Image augmentation \n",
    "- with Keras ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b917bbf",
   "metadata": {},
   "source": [
    "- The idea behind augmented images is that to make sure the neural network does not see the exact same image twice during the training, effectively creating an illusion to the the model under training that the training sample is much larger then it really is. \n",
    "\n",
    "- For a training data set of size 1000, for example, each epoch uses all of the data exactly once. If the batch size is 50, there will be 1000/50 = 20 passes or iterations in each epochs, making 20 updates on the initial (randomly assigned) weights and biases. If we select the number of epochs to be 30, it means the neural network will see each image (training data point) 30 times in total. \n",
    "\n",
    "- If we implement augmentation on this, with batch size = 50, and number of epoch = 30, during the training the model will not see the original data points directly but a random transformation of them as defined in the $ImageDataGenerator$. For each epoch, each  pass will include 50 of a transformed version of original image, covering all of the training images (transformed) in one epoch. For the next epoch, this will reapeat with a new set of transformed version of all original images. This way the model will be trianed with a \"new\" set of 1000 images in this epoch. For all of 30 epochs each of the origianl images will appear to the model in a slightly different version, via the transformation (augmentation). \n",
    "\n",
    "- In short, the model will see 30 versions of each of 1000 images at every epoch that are different but highly correlated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d1a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(rotation_range=20)\n",
    "iter=datagen.flow(samples,batch_size=2)\n",
    "batch=iter.next()\n",
    "plt.imshow(batch[0].astype('uint8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c607cb69",
   "metadata": {},
   "source": [
    "# 3. Exploring augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e8d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator rotation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rotation_range=30, width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,shear_range=0.2,zoom_range=0.2,\n",
    "                             horizontal_flip=True,fill_mode='nearest')\n",
    "datagen=ImageDataGenerator(rotation_range=30)\n",
    "# iterator: contains all possible random augmentation in the ranges as defined above\n",
    "aug_iter = datagen.flow(img_arr_, batch_size=1)\n",
    "\n",
    "# generate samples and plot\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,15))\n",
    "\n",
    "# generate batch of images\n",
    "for i in range(3):\n",
    "    if i>5:\n",
    "        break\n",
    "    else:\n",
    "        # convert to unsigned integers\n",
    "        image = next(aug_iter)[0].astype('uint8')\n",
    " \n",
    "        # plot image\n",
    "        ax[i].imshow(image)\n",
    "        ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f67dd3",
   "metadata": {},
   "source": [
    "# 4. Convolutional Neural Network: architecture\n",
    "- This is baseline model built on two fundamental principles of computer vision:  $\\textbf{1. Translational invariance}$ and $\\textbf{2. Spatial hiararchy}$. This is a simple model same as in notebook 1 but we have implemented with augmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61157869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2 \n",
    "\n",
    "modelB = models.Sequential()\n",
    "n_species = to_categorical(y_train).shape[1]\n",
    "# Add convolutional layer\n",
    "#model.add( layers.Conv3D(32, (3,3,3), activation='relu', input_shape=(224,224,3,1)) )\n",
    "modelB.add( tf.keras.layers.Conv2D(64, 3, activation='relu', input_shape=(224,224, 3)))\n",
    "modelB.add( layers.MaxPool2D((2,2), strides=2) ) \n",
    "# more layers \n",
    "modelB.add( layers.Conv2D(64, (3,3), activation='relu') )\n",
    "modelB.add( layers.MaxPool2D((2,2), strides=2))\n",
    "modelB.add( layers.Conv2D(128, (3,3), activation='relu') )\n",
    "\n",
    "modelB.add( layers.MaxPool2D((2,2), strides=2))\n",
    "modelB.add( layers.Conv2D(128, (3,3), activation='relu')) \n",
    "\n",
    "# .Flatten() will flatten the data for us\n",
    "modelB.add(layers.Flatten())\n",
    "modelB.add(layers.Dropout(.5))\n",
    "\n",
    "## # Now we'll add the fully connected layer >>> feedforward\n",
    "modelB.add(layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)) )\n",
    "modelB.add(layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "## Finally an output layer\n",
    "modelB.add(layers.Dense(n_species, activation='softmax'))\n",
    "\n",
    "modelB.compile(optimizer= optimizers.RMSprop(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "modelB.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0693d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL \n",
    "from keras.models import load_model\n",
    "modelB = load_model('convNet_birds_baselineAugm.h5')\n",
    "modelB.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803f1f94",
   "metadata": {},
   "source": [
    "# 5. We build data generator object for training set that supplies augmented data points for the model\n",
    "- validation set should not be augmented as it is not required for updating weights and biases \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa5f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40, width_shift_range=0.2,\n",
    "                             height_shift_range=0.2, shear_range=0.2, zoom_range=0.2,\n",
    "                             horizontal_flip=True, fill_mode='nearest')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255) # we don't augment validation images obviously! \n",
    "\n",
    "train_generator = train_datagen.flow(X_train,to_categorical(y_train), batch_size=32)\n",
    "validation_generator = val_datagen.flow(X_val,to_categorical(y_val), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f80c01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run the model \n",
    "batchSize = 32\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n",
    "## First make the validation set\n",
    "\n",
    "# ## Fit the model, and store the training history\n",
    "## using 100 epochs and a batch_size of 512\n",
    "n_epoch= 10\n",
    "historyB = modelB.fit(train_generator,steps_per_epoch=X_train.shape[0] // batchSize, epochs=n_epoch,\n",
    "                                validation_data=validation_generator,validation_steps = X_val.shape[0]//batchSize,\n",
    "                               verbose=1)\n",
    "\n",
    "historyB_dict = historyB.history\n",
    "print(historyB_dict.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a98fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelB.save(\"convNet_birds_baselineAug.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120e58da",
   "metadata": {},
   "source": [
    "# 6. Model performance\n",
    "- we save our array and retrain later and add the improvement to the existing list of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a155b22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run ONLY once\n",
    "valB_accuracy = []\n",
    "trainB_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8620be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tr, val, loss in zip(historyB_dict['accuracy'], historyB_dict['val_accuracy'], historyB_dict['val_loss']): \n",
    "    trainB_accuracy.append(tr)\n",
    "    valB_accuracy.append(val)\n",
    "    \n",
    "with open(\"train_accuracy\", \"w\") as fp:\n",
    "    json.dump(trainB_accuracy, fp)\n",
    "\n",
    "with open(\"validation_accuracy\", \"w\") as fp:\n",
    "    json.dump(valB_accuracy, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac05c3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_accuracy\", \"r\") as fp:\n",
    "    trainB_accuracy = json.load(fp)   \n",
    "with open(\"validation_accuracy\", \"r\") as fp:\n",
    "    valB_accuracy = json.load(fp)\n",
    "    \n",
    "N = len(valB_accuracy) #n_epoch-1\n",
    "# Display the metrics\n",
    "set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.plot(range(1,N+1), trainB_accuracy,'b--', markersize=5, alpha=0.5, label='training accuracy')\n",
    "plt.plot(range(1,N+1), valB_accuracy,'g--', markersize=5, alpha=0.7, label='validation accuracy')\n",
    "plt.plot(range(1,N+1), valB_accuracy,'ro', markersize=3, alpha=1, label='validation accuracy')\n",
    "plt.xlabel('Epoch', fontsize=16)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "\n",
    "plt.axhline(y=0.5, color='crimson', ls='--', alpha=1)\n",
    "plt.axhline(y=np.array(valB_accuracy).max(), color='k', ls='--')\n",
    "\n",
    "plt.text(1,np.round(np.array(valB_accuracy).max(),2)+0.01, \n",
    "         '$Max ~validation ~ accuracy$ = ' +str(np.round(np.array(valB_accuracy).max(),2)), \n",
    "         color='k', fontsize=12 )\n",
    "\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "#plt.savefig('perfomance_convNetBaseline_reg.pdf')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "set_style(\"white\")\n",
    "\n",
    "# Prediction power: any randomly selected image from the validation set\n",
    "n= np.random.binomial(100,0.5,1)[0]\n",
    "\n",
    "# we need to reshape input image to match the dimensions of sample \n",
    "predicted_bird = modelB.predict(X_val[n].reshape(-1, 224, 224, 3)).argmax()\n",
    "actual_bird = y_val[n]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(X_val[n].astype('uint8'), cmap='gray')\n",
    "plt.text(1,220, 'Predicted: ' + str(labelsDF.loc[labelsDF['label_index'] == predicted_bird, 'label'].values[0]),\n",
    "         color='yellow', fontsize=14 )\n",
    "\n",
    "plt.text(1,210, 'Actual: ' + str(labelsDF.loc[labelsDF['label_index'] == actual_bird, 'label'].values[0]),\n",
    "         color='brown', fontsize=14 )\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
