{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e069b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import set_style\n",
    "import seaborn as sns\n",
    "## This sets the plot style\n",
    "## to have a grid on a white background\n",
    "set_style(\"white\")\n",
    "\n",
    "# For preparing data \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#For neural network\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "## Importing the things\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras.utils import to_categorical\n",
    "import json\n",
    "\n",
    "#import skimage\n",
    "#print(skimage.__version__)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## Checks what is tensorflow running on\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b703a12b",
   "metadata": {},
   "source": [
    "# 1. Define directories that will be used for ImageDataGenerator to load train, validation, and test data sets\n",
    "- For this model, I used the data set that was selected by my group members with a theme that we would be classifying birds species found in the New York area. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffb3f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "original_dataset_dir = './birds_archive/'\n",
    "base_dir = './DataNY/'\n",
    "#os.mkdir(base_dir)\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "#os.mkdir(train_dir)\n",
    "\n",
    "validation_dir = os.path.join(base_dir, 'valid')\n",
    "#os.mkdir(validation_dir)\n",
    "\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "#os.mkdir(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35cad49",
   "metadata": {},
   "source": [
    "# 2. Data augmentation using ImageDataGenerator\n",
    "- note: we scale pixel values by diving them by 255, the maximum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43392cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "batchSize = 64\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40, width_shift_range=0.2,\n",
    "                             height_shift_range=0.2, shear_range=0.2, zoom_range=0.2,\n",
    "                             horizontal_flip=True, fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) # we don't augment validation/test images obviously! \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(224, 224), \n",
    "                                                    batch_size=batchSize, class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir,target_size=(224, 224),\n",
    "                                                        batch_size=batchSize_valid,class_mode='categorical')\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,target_size=(224, 224),\n",
    "                                batch_size=1, shuffle = False, color_mode=\"rgb\",class_mode='categorical')\n",
    "\n",
    "\n",
    "# we will use these for running our model\n",
    "n_training_images = train_generator.n #len(train_generator.labels), \n",
    "n_species = len(np.unique(train_generator.labels))\n",
    "n_valid_images = validation_generator.n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47150359",
   "metadata": {},
   "source": [
    "# 3. Pre-trained model: VGG16\n",
    "- Since our base model and that with augmented data did not quite resolve the overfitting issue, we resort to pre-trained model. This is because often smaller datasets require very long training time and still tend to overfit, resulting in poor prediction power for validation or test data. The idea of transfer learning is that we use a model that was previously trained on a very large data set. Since visual learning follows hiararchical structure the weights in convolutional layers in the pre-trained can stil be able to detect pattarns and pick up features at different parts of the input image, following the principle of statial invariance. \n",
    "\n",
    "- The main difference is the output layer. Every classificaton problem has its own number of classes so the output varies. For this reason, in tranfer learning, we load only the convolutional layers of a pre-trained model and add a feed-forward dense network, working as the classifier  for outr problem, on top of the convolutional base. The convolutional base from the pre-trained model is usually frozen in order to utilize the pre-trianed weights. In addiiton to being an efficient pattern-detecting network this save us a great deal of time and resources. \n",
    "\n",
    "- I implemented this method, which improved our validation accuracy largely.VGG16 is used for this purpose. It is among the most popular and highly performing model. Although, it is a heavy model and might be considered outdated but as a first project in neural network particularly with computer vision, I found VGG16 is great for understanding the inside architecture. I also used VGG19 but the performance differrence for our case is not much.\n",
    "\n",
    "- I also augmented our training data to improve accuracy. \n",
    "\n",
    "- Lasty, I applied another aspect of transfer learning, which is fine-tuning the last layer of the VGG model which accommodates better custom-fitting, and this improved the final validation accuracy to 95%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1866af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c7a512",
   "metadata": {},
   "source": [
    "# 4. Add a classier network on top on the VGG16 convolutional base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fe90cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelvggAugFT = models.Sequential()\n",
    "modelvggAugFT.add(conv_base) # <<----- frozen base \n",
    "\n",
    "modelvggAugFT.add(layers.Flatten())\n",
    "#modelvggAug.add(layers.Dense(256, activation='relu'))\n",
    "modelvggAugFT.add(layers.Dense(256, activation='relu'))#, input_dim=7*7*512) )\n",
    "modelvggAugFT.add(layers.Dropout(.5))\n",
    "modelvggAugFT.add(layers.Dense(128, activation='relu'))#, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "## Finally an output layer\n",
    "modelvggAugFT.add(layers.Dense(n_species, activation='softmax'))\n",
    "\n",
    "modelvggAugFT.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be94455d",
   "metadata": {},
   "source": [
    "# 5. Freeze all convolutional layers  except for the last one\n",
    "- This step helps improve the model performance since the outer convolutional layers are likely to recognize specific patterns related to birds. Hence, we free the outter 3 layers and train according to our data.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed27d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This is the number of trainable weights '\n",
    "'before partially freezing the conv base:', len(modelvggAugFT.trainable_weights))\n",
    "\n",
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "        \n",
    "print('This is the number of trainable weights '\n",
    "'after partially freezing the conv base:', len(modelvggAugFT.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c7097563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               6422784   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               12900     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,183,268\n",
      "Trainable params: 13,548,004\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL \n",
    "from keras.models import load_model\n",
    "modelvggAugFT = load_model('convNetvgg16_AugFT100NYa.h5')\n",
    "modelvggAugFT.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e07a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL \n",
    "# Check if I have frozen the correct layers\n",
    "for i, layer in enumerate(conv_base.layers[:20]):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f7b6a7",
   "metadata": {},
   "source": [
    "# 6. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2724a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Compile the model \n",
    "from keras import optimizers\n",
    "modelvggAugFT.compile(optimizer=optimizers.RMSprop(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Run the model \n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', mode='max', patience=20,  restore_best_weights=True)\n",
    "## First make the validation set\n",
    "\n",
    "# ## Fit the model, and store the training history\n",
    "## using 100 epochs and a batch_size of 512\n",
    "n_epoch= 10\n",
    "historyvggAugFT = modelvggAugFT.fit_generator(train_generator,steps_per_epoch = n_training_images//batchSize, epochs = n_epoch,\n",
    "                                validation_data = validation_generator,\n",
    "                                validation_steps = 1 , callbacks=[callback], verbose=1)\n",
    "\n",
    "historyvggAugFT_dict = historyvggAugFT.history\n",
    "print(historyvggAugFT_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d183c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelvggAugFT.save(\"convNetvgg16_AugFT100NYa.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1795973",
   "metadata": {},
   "source": [
    "# 6. Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877f2e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run ONLY once\n",
    "val_accuracy = []\n",
    "train_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5ee42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tr, val, loss in zip(historyvggAugFT_dict['accuracy'], historyvggAugFT_dict['val_accuracy'], historyvggAugFT_dict['val_loss']): \n",
    "    train_accuracy.append(tr)\n",
    "    val_accuracy.append(val)\n",
    "    \n",
    "with open(\"train_accuracy\", \"w\") as fp:\n",
    "    json.dump(train_accuracy, fp)\n",
    "\n",
    "with open(\"validation_accuracy\", \"w\") as fp:\n",
    "    json.dump(val_accuracy, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b226b549",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_accuracy\", \"r\") as fp:\n",
    "    train_accuracy = json.load(fp)   \n",
    "with open(\"validation_accuracy\", \"r\") as fp:\n",
    "    val_accuracy = json.load(fp)\n",
    "    \n",
    "N = len(val_accuracy) #n_epoch-1\n",
    "# Display the metrics\n",
    "set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.plot(range(1,N+1), train_accuracy,'b--^', markersize=5,label='training accuracy')\n",
    "plt.plot(range(1,N+1), val_accuracy,'g--o', markersize=5, alpha=0.8, label='validation accuracy')\n",
    "plt.xlabel('Epoch', fontsize=16)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "\n",
    "plt.axhline(y=0.5, color='crimson', ls='--', alpha=1)\n",
    "plt.axhline(y=np.array(val_accuracy).max(), color='k', ls='--')\n",
    "\n",
    "plt.text(1,np.round(np.array(val_accuracy).max(),2)+0.01, \n",
    "         '$Max ~validation ~ accuracy$ = ' +str(np.round(np.array(val_accuracy).max(),2)), \n",
    "         color='k', fontsize=12 )\n",
    "\n",
    "plt.title('Sample size='+str(n_training_images+ n_valid_images)+', with'+str(n_species)+' species', fontsize=20, loc='center', pad=None)\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "#plt.savefig('performance_vgg16AugFT100NY.pdf')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2a807d",
   "metadata": {},
   "source": [
    "# 7. Model performance based on a random image from test data folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ed1b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_style(\"white\")\n",
    "# Prediction power\n",
    "n=np.random.binomial(test_generator.n,0.5,1)[0]\n",
    "#plt.imshow(test_image)\n",
    "#plt.show()\n",
    "#filenames = test_generator.filenames\n",
    "\n",
    "test_image = tf.keras.utils.load_img(test_generator.filepaths[n],grayscale=False,color_mode='rgb',\n",
    "                target_size=None,interpolation='nearest',keep_aspect_ratio=False)\n",
    "\n",
    "predicted_bird = modelvggAugFT.predict(image.img_to_array(test_image).reshape(-1,224,224,3)).argmax()\n",
    "actual_bird = test_generator.classes[n]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(test_image)#, cmap='gray')\n",
    "plt.text(1,220, 'Predicted: ' + str(labelsDF.loc[labelsDF['label_index'] == predicted_bird, 'labels'].values[0]),\n",
    "         color='yellow', fontsize=14 )\n",
    "\n",
    "plt.text(1,210, 'Actual: ' + str(labelsDF.loc[labelsDF['label_index'] == actual_bird, 'labels'].values[0]),\n",
    "         color='brown', fontsize=14 )\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1114603",
   "metadata": {},
   "source": [
    "# # 7. Model performance on the test data folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cc04e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelvggAugFT = load_model('convNetvgg16_AugFT100NYa.h5')\n",
    "labelsDF = pd.read_csv('labelsDF.csv')\n",
    "\n",
    "img_list = []\n",
    "\n",
    "for PATH in test_generator.filepaths:\n",
    "    img = tf.keras.utils.load_img(PATH,grayscale=False,color_mode='rgb',\n",
    "                    target_size=None,interpolation='nearest',keep_aspect_ratio=False)\n",
    "\n",
    "    img_list.append(image.img_to_array(img))\n",
    "\n",
    "    \n",
    "test_image_arr = np.array(img_list)\n",
    "test_image_arr.shape\n",
    "\n",
    "test_pred = modelvggAugFT.predict(test_image_arr)    \n",
    "    \n",
    "set_style(\"white\")\n",
    "\n",
    "#predicted_array = modelvggAugFT.predict(X_val.reshape(-1,224,224,3))\n",
    "def imageArray_predict(model, PATH):\n",
    "\n",
    "    img = tf.keras.utils.load_img(PATH,grayscale=False,color_mode='rgb',\n",
    "                    target_size=None,interpolation='nearest',keep_aspect_ratio=False)\n",
    "\n",
    "    predicted_bird = test_pred[n].argmax()\n",
    "    actual_bird = test_generator.classes[n]\n",
    "        \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(img)#, cmap='gray')\n",
    "    plt.text(1,220, 'Predicted: ' + str(labelsDF.loc[labelsDF['label_index'] == predicted_bird, 'labels'].values[0]),\n",
    "             color='yellow', fontsize=14 )\n",
    "\n",
    "    plt.text(1,210, 'Actual: ' + str(labelsDF.loc[labelsDF['label_index'] == actual_bird, 'labels'].values[0]),\n",
    "             color='brown', fontsize=14 )\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "def pred_acc(model, PATH):\n",
    "    img = tf.keras.utils.load_img(PATH,grayscale=False,color_mode='rgb',\n",
    "                    target_size=None,interpolation='nearest',keep_aspect_ratio=False)\n",
    "    \n",
    "    predicted_bird = test_pred[n].argmax()# model.predict(image.img_to_array(img).reshape(-1,224,224,3)).argmax()\n",
    "    actual_bird = test_generator.classes[n]\n",
    "    return (predicted_bird == actual_bird)*1\n",
    "\n",
    "# check for the first n images in the validation set \n",
    "# note: zip is a useful function for iterating in parallel \n",
    "n1 = 0#np.random.binomial(test_generator.n,0.5,1)[0]\n",
    "n2= 499 # + n1#n1 + np.random.binomial(10, 0.5, 1)[0]\n",
    "\n",
    "accuracy=0\n",
    "for n in (range(n1,n2)):\n",
    "    #print(n)\n",
    "    imageArray_predict(modelvggAugFT, test_generator.filepaths[n])  # <<<<<<<<<<<<< show images \n",
    "    accuracy += pred_acc(modelvggAugFT, test_generator.filepaths[n])\n",
    "\n",
    "\n",
    "print(\"sample accuracy =\", accuracy, 'out of', (n2-n1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
