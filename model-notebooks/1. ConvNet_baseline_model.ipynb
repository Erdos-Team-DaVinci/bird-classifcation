{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a197aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import set_style\n",
    "import seaborn as sns\n",
    "## This sets the plot style\n",
    "## to have a grid on a white background\n",
    "set_style(\"white\")\n",
    "\n",
    "#For machine learning methods\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#For neural network\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "## Importing the things\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras.utils import to_categorical\n",
    "import json\n",
    "\n",
    "import skimage\n",
    "print(skimage.__version__)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## Checks what is tensorflow running on\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "## This imports datasets stored in keras\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a49b0c",
   "metadata": {},
   "source": [
    "# Sample of size 15,000 and 100 labels\n",
    "- Note: for the baseline model we used randomly selected sample of images out of the original data set. For our final model, we use specific group 100 bird species found in the New York area. We compare the relative performace between the two models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d2b109",
   "metadata": {},
   "source": [
    "# 1. Data preprocessing \n",
    "- Here I have a new dataset for training. In this case, I have selected 100 randomly chosen bird species out of 400 in total. The selected labels are used for running a query in the original database (birds.csv) to collect all images and data points correspoinding to these 100 labels, in total $15694$ data points or observations. Since these labels were randomly selected the numerical indices are not orderly unlike the entire dataset. This causes a problem with the output neron layer in the feed-forward architecture, with many of the images having unclassified labels. So I have assigned new numerical labels $0 - 99$ to each image. This way we can use tensorflow method (to_categorical) to convert the digits to $[1,0,0,..0]$ format compatible with softmax probability output.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfc7eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "birds_db = pd.read_csv('./birds_archive/birds.csv')\n",
    "birds_db.value_counts('labels')\n",
    "birds_class = pd.read_csv('./birds_archive/class_dict.csv')\n",
    "birds_names = pd.read_csv('./birds_archive/birds latin names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae9ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "birds_names_subset = birds_names.sample(100, random_state=42)\n",
    "birds_names_subset = birds_names_subset.rename(columns={'class':'labels'})\n",
    "print(birds_names_subset)\n",
    "\n",
    "birds_db_subset = birds_db[birds_db['labels'].isin(birds_names_subset['labels'])].dropna()\n",
    "birds_db_subset = birds_db_subset.reset_index()\n",
    "birds_db_subset\n",
    "\n",
    "label_dict = {i:birds_names_subset['labels'].values[i] for i in range(len(birds_names_subset))}\n",
    "labelsDF = pd.DataFrame(label_dict.items(), columns=['label_index','label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4769d8",
   "metadata": {},
   "source": [
    "# 2. Import images\n",
    "- Import all images corresponding to 100 labels selected above and converted them an array. For this model, we implement scikit-learn tools to split the data into train test split for validation purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc13dcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# this piece loads image data into a list and a numpy array \n",
    "bird_labels = []\n",
    "bird_label_num = []\n",
    "birdImage_list_jpg = []\n",
    "birdImage_list = []\n",
    "\n",
    "for indx, filepath, label in zip(range(len(birds_db_subset)), birds_db_subset.filepaths, birds_db_subset.labels):\n",
    "    try:\n",
    "        bird_labels.append(label)\n",
    "        bird_label_num.append(labelsDF.loc[labelsDF['label'] == label, 'label_index'].values[0])\n",
    "        #print(filepath)\n",
    "        img = tf.keras.utils.load_img(\n",
    "                './birds_archive/Data/'+filepath,\n",
    "                grayscale=False,\n",
    "                color_mode='rgb',\n",
    "                target_size=None,\n",
    "                interpolation='nearest',\n",
    "                keep_aspect_ratio=False)\n",
    "        \n",
    "        # list of bird images in jpg format \n",
    "        birdImage_list_jpg.append(img)  \n",
    "        \n",
    "        img_arr = np.array(img)\n",
    "        # List containng all bird images each in array format \n",
    "        birdImage_list.append(img_arr)\n",
    "    except (TypeError, IndexError) as e:\n",
    "        pass\n",
    "\n",
    "# Numpy array N x 224x224x3 containing all bird images \n",
    "birdImage_arr = np.array(birdImage_list) \n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(birdImage_arr, (pd.DataFrame(bird_label_num)[0]).values,\n",
    "                                                                          test_size=0.15, shuffle=True, random_state=44)\n",
    "X_train = X_train / 255\n",
    "X_val = X_val / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c886f64",
   "metadata": {},
   "source": [
    "# 3. Exploring train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e07da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.keras.utils.load_img(\n",
    "                './birds_archive/Data/'+filepath,\n",
    "                grayscale=False,\n",
    "                color_mode='rgb',\n",
    "                target_size=None,\n",
    "                interpolation='nearest',\n",
    "                keep_aspect_ratio=False)\n",
    "\n",
    "\n",
    "i, (im1, im2, im3, im4) = plt.subplots(1, 4, sharey=True)\n",
    "i.set_figwidth(20) \n",
    "im1.imshow(img)  #Original image\n",
    "im2.imshow(np.array(img)[:, : , 0]) #Red\n",
    "im3.imshow(np.array(img)[:, : , 1]) #Green\n",
    "im4.imshow(np.array(img)[:, : , 2]) #Blue\n",
    "i.suptitle('Original & RGB image channels')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1718d969",
   "metadata": {},
   "source": [
    "# 4. Convolutional Neural Network: architecture \n",
    "- This is baseline model built on two fundamental principles of computer vision:  $\\textbf{1. Translational invariance}$ and $\\textbf{2. Spatial hiararchy}$. This is a simple model with a few  convolutional (invariance) and pooling (hiararchy) layers. The depth values are chosen based on the complexity of input feature space as well as the number of softmax output neurons. Fiiters and other parameters are kept standard.I also implement regularization cconditions to feed-forward as well as convoluitonal layers in order to address overfitting.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f811f5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2 \n",
    "\n",
    "modelB = models.Sequential()\n",
    "n_species = to_categorical(y_train).shape[1]\n",
    "# Add convolutional layer\n",
    "#model.add( layers.Conv3D(32, (3,3,3), activation='relu', input_shape=(224,224,3,1)) )\n",
    "modelB.add( tf.keras.layers.Conv2D(64, 3, activation='relu', input_shape=(224,224, 3)))\n",
    "modelB.add( layers.MaxPool2D((2,2), strides=2) ) \n",
    "# more layers \n",
    "modelB.add( layers.Conv2D(64, (3,3), activation='relu') )\n",
    "modelB.add( layers.MaxPool2D((2,2), strides=2))\n",
    "modelB.add( layers.Conv2D(128, (3,3), activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)) )\n",
    "\n",
    "modelB.add( layers.MaxPool2D((2,2), strides=2))\n",
    "modelB.add( layers.Conv2D(128, (3,3), activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))) \n",
    "\n",
    "# .Flatten() will flatten the data for us\n",
    "modelB.add(layers.Flatten())\n",
    "modelB.add(layers.Dropout(.5))\n",
    "\n",
    "## # Now we'll add the fully connected layer >>> feedforward\n",
    "modelB.add(layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)) )\n",
    "modelB.add(layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "## Finally an output layer\n",
    "modelB.add(layers.Dense(n_species, activation='softmax'))\n",
    "\n",
    "modelB.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ccde79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL cell for loading our saved model\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "modelB = load_model('convNet_birds_baseline.h5')\n",
    "modelB.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1629bf31",
   "metadata": {},
   "source": [
    "# 5. ConvNet Training -  100 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5aafaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Compile the model \n",
    "\n",
    "modelB.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n",
    "## First make the validation set\n",
    "\n",
    "# ## Fit the model, and store the training history\n",
    "## using 100 epochs and a batch_size of 512\n",
    "n_epoch= 5\n",
    "historyB = modelB.fit(X_train, to_categorical(y_train), epochs=n_epoch, batch_size=512,\n",
    "                   validation_data=(X_val, to_categorical(y_val)), callbacks=[callback], verbose=1)\n",
    "\n",
    "historyB_dict = historyB.history\n",
    "print(historyB_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8822c63b",
   "metadata": {},
   "source": [
    "# 6. Save model to use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4640de",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelB.save(\"convNet_birds_baseline_reg.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eefc619",
   "metadata": {},
   "source": [
    "# 7. Model performance\n",
    "- we save our array and retrain later and add the improvement to the existing list of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ba3501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run ONLY once\n",
    "valB_accuracy = []\n",
    "trainB_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f2d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tr, val, loss in zip(historyB_dict['accuracy'], historyB_dict['val_accuracy'], historyB_dict['val_loss']): \n",
    "    trainB_accuracy.append(tr)\n",
    "    valB_accuracy.append(val)\n",
    "    \n",
    "with open(\"train_accuracy\", \"w\") as fp:\n",
    "    json.dump(trainB_accuracy, fp)\n",
    "\n",
    "with open(\"validation_accuracy\", \"w\") as fp:\n",
    "    json.dump(valB_accuracy, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07295d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_accuracy\", \"r\") as fp:\n",
    "    trainB_accuracy = json.load(fp)   \n",
    "with open(\"validation_accuracy\", \"r\") as fp:\n",
    "    valB_accuracy = json.load(fp)\n",
    "    \n",
    "N = len(valB_accuracy) #n_epoch-1\n",
    "# Display the metrics\n",
    "set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(range(1,N+1), trainB_accuracy,'b--^', markersize=5,label='training accuracy')\n",
    "plt.plot(range(1,N+1), valB_accuracy,'g--o', markersize=5, alpha=0.8, label='validation accuracy')\n",
    "plt.xlabel('Epoch', fontsize=16)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "\n",
    "plt.axhline(y=0.5, color='crimson', ls='--', alpha=1)\n",
    "plt.axhline(y=np.array(valB_accuracy).max(), color='k', ls='--')\n",
    "\n",
    "plt.text(1,np.round(np.array(valB_accuracy).max(),2)+0.01, \n",
    "         '$Max ~validation ~ accuracy$ = ' +str(np.round(np.array(valB_accuracy).max(),2)), \n",
    "         color='k', fontsize=12 )\n",
    "\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "plt.savefig('perfomance_convNetBaseline.pdf')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "set_style(\"white\")\n",
    "# Prediction power\n",
    "n=np.random.binomial(100,0.5,1)[0]\n",
    "predicted_bird = modelB.predict(X_val)[n].argmax()\n",
    "actual_bird = y_val[n]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(X_val[n], cmap='gray')\n",
    "plt.text(1,220, 'Predicted: ' + str(labelsDF.loc[labelsDF['label_index'] == predicted_bird, 'label'].values[0]),\n",
    "         color='yellow', fontsize=14 )\n",
    "\n",
    "plt.text(1,210, 'Actual: ' + str(labelsDF.loc[labelsDF['label_index'] == actual_bird, 'label'].values[0]),\n",
    "         color='brown', fontsize=14 )\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
